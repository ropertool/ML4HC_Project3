{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression on TfidfVectorizer (Baseline)\n",
    "A common approach to NLP is to run (multinomial) Logistic Regression on the vectorized words. Making use of the sklearn library, TfidfVectorizer internally gets the CountVectorizer representation of token counts and transforms it with Tfidf (term frquency inverse document frequency).\n",
    "\n",
    "\"The goal of using tf-idf instead of the raw frequencies of occurrence of a token in a given document is to scale down the impact of tokens that occur very frequently in a given corpus and that are hence empirically less informative than features that occur in a small fraction of the training corpus.\" (https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the baseline result, we ran TfidfVectorizer+LogisticRegression with both preprocessed and unprocessed data. We achieved better results with no preprocessing. Even after varying the used preprocessing methods, the results were best on the uncleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unprocessed_data(filename): # train, dev, test\n",
    "    labels = ['background', 'objective', 'methods', 'results', 'conclusions']\n",
    "    data = []\n",
    "    with open(os.path.join('./PubMed_200k_RCT', f'{filename}.txt'), 'r') as f:\n",
    "        data = f.readlines()\n",
    "    output_labels = []  # define an empty list to store the labels\n",
    "    output_sentences = []  # define an empty list to store the sentences\n",
    "\n",
    "    for line in tqdm(data):\n",
    "        line = line.split()\n",
    "        if len(line) >= 2:\n",
    "            label = line[0].lower()\n",
    "            if label not in labels:\n",
    "                continue\n",
    "            else:\n",
    "                labelnum = labels.index(label)\n",
    "                \n",
    "                output_labels.append(labelnum)\n",
    "                output_sentences.append(' '.join(line[1:]))\n",
    "    return output_labels, output_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 2593169/2593169 [00:05<00:00, 489593.99it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 33932/33932 [00:00<00:00, 507834.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 34493/34493 [00:00<00:00, 508313.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Result on validation set:\n",
      "F1 Score: micro 0.8243121802848058, macro 0.7572239244299099, weighted 0.8210974554468179\n",
      "Result on test set:\n",
      "F1 Score: micro 0.8247041670904961, macro 0.7573541905307171, weighted 0.8214023347513191\n"
     ]
    }
   ],
   "source": [
    " def evaluate(y_pred, y):\n",
    "    micro = f1_score(y, y_pred, average='micro')\n",
    "    macro = f1_score(y, y_pred, average='macro')\n",
    "    weighted = f1_score(y, y_pred, average='weighted')\n",
    "    print(f'F1 Score: micro {micro}, macro {macro}, weighted {weighted}')\n",
    "\n",
    "def run_and_evaluate_baseline():\n",
    "    labels, corpus = get_unprocessed_data('train')\n",
    "    labels_valid, corpus_valid = get_unprocessed_data('dev')\n",
    "    labels_test, corpus_test = get_unprocessed_data('test')\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    scikit_log_reg = LogisticRegression(solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000, verbose=1)\n",
    "    model=scikit_log_reg.fit(X, labels)\n",
    "    \n",
    "    X_valid = vectorizer.transform(corpus_valid)\n",
    "    X_test = vectorizer.transform(corpus_test)\n",
    "    y_pred_valid = model.predict(X_valid)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    print('Result on validation set:')\n",
    "    evaluate(y_pred_valid, labels_valid)\n",
    "    print('Result on test set:')\n",
    "    evaluate(y_pred_test, labels_test)\n",
    "\n",
    "run_and_evaluate_baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network with GRU layers\n",
    "Recurrent Neural Networks are used because of their ability to store long-term memory and to account for new inputs as effectively as possible. (https://compstat-lmu.github.io/seminar_nlp_ss20/recurrent-neural-networks-and-their-applications-in-nlp.html)\n",
    "\n",
    "GRU stands for Gated Recurrent Unit. GRU has two gates: reset and update. \n",
    "\n",
    "Comparing GRU and LSTM, GRU controls flow infromation like LSTM, but without using memory units. GRUs simpler, easier to modify, and train a lot faster (computationally more efficient).\n",
    "\n",
    "LSTMs have a separate forget and update gate which makes them more sophisticated. LSTM should outperform GRUs in modeling long distance relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liine\\anaconda3\\envs\\ml4h\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 2593169/2593169 [02:27<00:00, 17580.95it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 33932/33932 [00:02<00:00, 15943.31it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 34493/34493 [00:01<00:00, 17958.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# get_data function should be defined above and removes this import\n",
    "from preprocessing import get_data\n",
    "\n",
    "# these are hopefully defined above in the notebook\n",
    "labels, corpus = get_data('train')\n",
    "labels_valid, corpus_valid = get_data('dev')\n",
    "labels_test, corpus_test = get_data('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is necessary when running tensorflow locally with GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put these cells above as well?\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our own f1_weighted function, which compares the ground truth labels (as numbers) to the softmax prediction array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should be above as well?\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "def f1_weighted(label, pred):\n",
    "    num_classes = 5\n",
    "    label = K.cast(K.flatten(label), 'int32')\n",
    "    true = K.one_hot(label, num_classes)\n",
    "    pred_labels = K.argmax(pred, axis=-1)\n",
    "    pred = K.one_hot(pred_labels, num_classes)\n",
    "\n",
    "    ground_positives = K.sum(true, axis=0) + K.epsilon()  # = TP + FN\n",
    "    pred_positives = K.sum(pred, axis=0) + K.epsilon()  # = TP + FP\n",
    "    true_positives = K.sum(true * pred, axis=0) + K.epsilon()  # = TP\n",
    "\n",
    "    precision = true_positives / pred_positives\n",
    "    recall = true_positives / ground_positives\n",
    "\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "\n",
    "    weighted_f1 = f1 * ground_positives / K.sum(ground_positives)\n",
    "    weighted_f1 = K.sum(weighted_f1)\n",
    "\n",
    "    return weighted_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our GRU model is relatively simple.\n",
    "1. We start off with a text vectorization layer, which we adapt to the corpus to initialize it with the known vocabulary.\n",
    "2. Our embedding layer is initialized with weights from our best performing Word2Vec model. Here we set mask_zero=True, to avoid bringing in new information.\n",
    "3. Next come our GRU layers. We make use of the Bidirectional layer which allows us to make predictions from both previous and following time steps.\n",
    "4. With the Dense layer of size 5, we model the output to predict the probability of the text belonging to each of the 5 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gru_model():\n",
    "    w2v = Word2Vec.load('trained_models/word2vec_100_7_15.model')\n",
    "    weight_matrix = w2v.wv.vectors\n",
    "    vocab_size = weights.shape[0]\n",
    "    embedding_dim = weights.shape[1]\n",
    "    \n",
    "    num_classes = 5\n",
    "    vectorize_layer = TextVectorization(max_tokens=vocab_size, output_mode='int')\n",
    "    vectorize_layer.adapt(corpus)\n",
    "\n",
    "    model = Sequential([\n",
    "        vectorize_layer,\n",
    "        Embedding(vocab_size, embedding_dim, embeddings_initializer=Constant(weight_matrix), mask_zero=True),\n",
    "        Bidirectional(GRU(embedding_dim, return_sequences=True)),\n",
    "        Bidirectional(GRU(32)),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[acc, f1_weighted])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippet trains and saves our GRU model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gru(model):\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    model_name = f'GRU_{timestr}'\n",
    "    model_save_path = f'models/{model_name}'\n",
    "    epochs = 20\n",
    "    batch = 32\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=f'./logs/{model_name}', update_freq='batch')\n",
    "    model.fit(corpus, labels, validation_data=(corpus_valid, labels_valid), epochs=epochs, batch_size=batch,\n",
    "                  callbacks=[tensorboard_callback])\n",
    "\n",
    "    model.save(model_save_path)\n",
    "    print(f'Model saved: {model_save_path}')\n",
    "\n",
    "# train_gru(get_gru_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded\n",
      "904/904 [==============================] - 7s 8ms/step - loss: 0.4641 - sparse_categorical_accuracy: 0.8280 - f1_weighted: 0.8271\n",
      "Valid loss, acc, f1: [0.4640914499759674, 0.8280428647994995, 0.8270767331123352]\n",
      "922/922 [==============================] - 8s 8ms/step - loss: 0.4792 - sparse_categorical_accuracy: 0.8262 - f1_weighted: 0.8252\n",
      "Test loss, acc, f1: [0.47924497723579407, 0.826227068901062, 0.8251857757568359]\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('GRU_checkpoint', custom_objects={\"f1_weighted\": f1_weighted})\n",
    "print(f'Model successfully loaded')\n",
    "# print(f'Train loss, acc, f1: {loaded_model.evaluate(corpus, labels)}')\n",
    "print(f'Valid loss, acc, f1: {loaded_model.evaluate(corpus_valid, labels_valid)}')\n",
    "print(f'Test loss, acc, f1: {loaded_model.evaluate(corpus_test, labels_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
